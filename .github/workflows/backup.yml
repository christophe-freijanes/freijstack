name: ðŸ’¾ Scheduled Cloud Backup

on:
  schedule:
    # Tous les jours Ã  3h UTC (4h Paris en hiver, 5h en Ã©tÃ©)
    - cron: '0 3 * * *'
  
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to backup'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
      provider:
        description: 'Cloud provider (leave empty for auto-detect all)'
        required: false
        type: choice
        options:
          - ''
          - s3
          - azure
          - gcs
          - b2
          - spaces
          - wasabi

env:
  # Default to production for scheduled runs
  TARGET_ENV: ${{ github.event_name == 'workflow_dispatch' && inputs.environment || 'production' }}
  PROVIDER: ${{ github.event_name == 'workflow_dispatch' && inputs.provider || '' }}

jobs:
  backup-production:
    name: ðŸ’¾ Backup Production to Cloud
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'production')
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ” Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.VPS_SSH_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H ${{ secrets.VPS_SSH_HOST }} >> ~/.ssh/known_hosts
      
      - name: ðŸ”’ Mask sensitive values
        run: |
          echo "::add-mask::${{ secrets.VPS_SSH_USER }}"
          echo "::add-mask::${{ secrets.VPS_SSH_HOST }}"
          echo "::add-mask::${{ secrets.VPS_SSH_USER }}@${{ secrets.VPS_SSH_HOST }}"
      
      - name: ðŸ’¾ Run Cloud Backup
        env:
          # AWS S3
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
          
          # Azure (optionnel)
          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
          AZURE_CONTAINER: ${{ secrets.AZURE_CONTAINER }}
          
          # GCS (optionnel)
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          
          # Backblaze B2 (optionnel)
          B2_APPLICATION_KEY_ID: ${{ secrets.B2_APPLICATION_KEY_ID }}
          B2_APPLICATION_KEY: ${{ secrets.B2_APPLICATION_KEY }}
          B2_BUCKET_NAME: ${{ secrets.B2_BUCKET_NAME }}
          
          # Notifications
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          echo "ðŸš€ Starting backup for production..."
          echo "Provider: ${{ env.PROVIDER || 'auto-detect all configured' }}"
          
          # Copier le script sur le VPS
          scp -i ~/.ssh/deploy_key scripts/backup-to-cloud.sh \
            ${{ secrets.VPS_SSH_USER }}@${{ secrets.VPS_SSH_HOST }}:/tmp/backup-to-cloud.sh
          
          # ExÃ©cuter le backup avec toutes les variables d'environnement
          ssh -i ~/.ssh/deploy_key ${{ secrets.VPS_SSH_USER }}@${{ secrets.VPS_SSH_HOST }} << 'BACKUP_SCRIPT'
            # Export all environment variables
            export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
            export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
            export AWS_S3_BUCKET="${{ secrets.AWS_S3_BUCKET }}"
            export AWS_REGION="${{ secrets.AWS_REGION || 'us-east-1' }}"
            
            export AZURE_STORAGE_ACCOUNT="${{ secrets.AZURE_STORAGE_ACCOUNT }}"
            export AZURE_STORAGE_KEY="${{ secrets.AZURE_STORAGE_KEY }}"
            export AZURE_CONTAINER="${{ secrets.AZURE_CONTAINER }}"
            
            export GCS_BUCKET="${{ secrets.GCS_BUCKET }}"
            
            export B2_APPLICATION_KEY_ID="${{ secrets.B2_APPLICATION_KEY_ID }}"
            export B2_APPLICATION_KEY="${{ secrets.B2_APPLICATION_KEY }}"
            export B2_BUCKET_NAME="${{ secrets.B2_BUCKET_NAME }}"
            
            export SLACK_WEBHOOK_URL="${{ secrets.SLACK_WEBHOOK_URL }}"
            export DISCORD_WEBHOOK_URL="${{ secrets.DISCORD_WEBHOOK_URL }}"
            
            # Make script executable
            chmod +x /tmp/backup-to-cloud.sh
            
            # Run backup
            /tmp/backup-to-cloud.sh production "${{ env.PROVIDER }}"
            
            # Cleanup
            rm -f /tmp/backup-to-cloud.sh
          BACKUP_SCRIPT
      
      - name: âœ… Backup Success
        if: success()
        run: |
          echo "âœ… Production backup completed successfully!"
          echo "Environment: production"
          echo "Provider: ${{ env.PROVIDER || 'all configured providers' }}"
          echo "Timestamp: $(date)"
      
      - name: âŒ Backup Failed
        if: failure()
        run: |
          echo "âŒ Production backup failed!"
          echo "Check logs above for details"
          exit 1

  backup-staging:
    name: ðŸ’¾ Backup Staging to Cloud
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && inputs.environment == 'staging'
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ” Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.VPS_SSH_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H ${{ secrets.VPS_SSH_HOST }} >> ~/.ssh/known_hosts
      
      - name: ðŸ”’ Mask sensitive values
        run: |
          echo "::add-mask::${{ secrets.VPS_SSH_USER }}"
          echo "::add-mask::${{ secrets.VPS_SSH_HOST }}"
      
      - name: ðŸ’¾ Run Cloud Backup
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
        run: |
          echo "ðŸš€ Starting backup for staging..."
          
          scp -i ~/.ssh/deploy_key scripts/backup-to-cloud.sh \
            ${{ secrets.VPS_SSH_USER }}@${{ secrets.VPS_SSH_HOST }}:/tmp/backup-to-cloud.sh
          
          ssh -i ~/.ssh/deploy_key ${{ secrets.VPS_SSH_USER }}@${{ secrets.VPS_SSH_HOST }} << 'BACKUP_SCRIPT'
            export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
            export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
            export AWS_S3_BUCKET="${{ secrets.AWS_S3_BUCKET }}"
            export AWS_REGION="${{ secrets.AWS_REGION || 'us-east-1' }}"
            
            chmod +x /tmp/backup-to-cloud.sh
            /tmp/backup-to-cloud.sh staging "${{ env.PROVIDER }}"
            rm -f /tmp/backup-to-cloud.sh
          BACKUP_SCRIPT
      
      - name: âœ… Backup Success
        if: success()
        run: |
          echo "âœ… Staging backup completed successfully!"

  notify:
    name: ðŸ“¢ Notify Backup Status
    runs-on: ubuntu-latest
    needs: [backup-production, backup-staging]
    if: always()
    
    steps:
      - name: Check Status
        run: |
          if [ "${{ needs.backup-production.result }}" = "success" ] || [ "${{ needs.backup-staging.result }}" = "success" ]; then
            echo "âœ… Backup job(s) completed successfully"
          else
            echo "âŒ Some backup job(s) failed"
            echo "Production: ${{ needs.backup-production.result }}"
            echo "Staging: ${{ needs.backup-staging.result }}"
          fi
